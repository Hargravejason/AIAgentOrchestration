using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.IO;
using System.Linq;
using System.Runtime.CompilerServices;
using System.Text.RegularExpressions;
using System.Threading.Tasks;
//using DuckDB;
using Microsoft.SemanticKernel;

namespace AgentTools;

// DTOs ---------------------------------------------------------------
public sealed record ColumnProfile(
    string Name,
    string Normalized,
    string LogicalType,
    double NullPct,
    long DistinctCount,
    string? Min = null,
    string? Max = null,
    double? Avg = null,
    string[]? Top = null,
    string[]? Examples = null);

public sealed record SchemaCard(
    long Rows,
    string[] TimeCandidates,
    List<ColumnProfile> Columns
);

/// <summary>
/// Session-scoped CSV analytics tool belt for Semantic Kernel.
/// - Ingests a user CSV into DuckDB :memory:
/// - Builds a compact schema/profile card
/// - Exposes query + trend functions with strict row caps
/// - Everything is ephemeral per instance
/// </summary>
//public sealed class SessionCsvAgent : IAsyncDisposable
//{
//  private readonly DuckDBConnection _conn;
//  private readonly string _table;
//  private string? _tempCsvPath; // for stream ingestion
//  private SchemaCard? _schema;

//  public SessionCsvAgent(string tableName = "t")
//  {
//    _table = SanitizeIdent(tableName);
//    _conn = new DuckDBConnection("DataSource=:memory:;");
//    _conn.Open();
//  }

//  // ------------------------ Ingestion -----------------------------
//  /// <summary>Load a CSV stream into the in-memory DuckDB table.</summary>
//  public async Task LoadCsvAsync(Stream csv, bool detectTypes = true)
//  {
//    // Persist to a temp file so DuckDB can read it efficiently
//    _tempCsvPath = Path.GetTempFileName();
//    await using (var fs = File.Create(_tempCsvPath))
//    {
//      await csv.CopyToAsync(fs);
//    }

//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = $@
//            "CREATE TABLE {_table} AS\n" +
//            "SELECT * FROM read_csv_auto('{_tempCsvPath}', AUTO_DETECT={Bool(detectTypes)}, SAMPLE_SIZE=-1, IGNORE_ERRORS=TRUE);";
//    cmd.ExecuteNonQuery();

//    // Basic cleanup: trim column names, create safe identifiers
//    NormalizeColumnNames();

//    // Build schema card once
//    _schema = await BuildSchemaAsync();
//  }

//  // ------------------------ Introspection ------------------------
//  [KernelFunction, Description("Return the schema card (columns, types, examples, time candidates).")]
//  public SchemaCard GetSchemaCard()
//  {
//    EnsureSchema();
//    return _schema!;
//  }

//  [KernelFunction, Description("List columns and their logical types.")]
//  public List<Dictionary<string, object>> ListColumns()
//  {
//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = $"PRAGMA table_info('{_table}');"; // cid, name, type, notnull, dflt_value, pk
//    using var rdr = cmd.ExecuteReader();
//    var rows = ReadRows(rdr);

//    // project name + type
//    return rows.Select(r => new Dictionary<string, object>
//    {
//      ["name"] = r["name"],
//      ["type"] = r["type"],
//    }).ToList();
//  }

//  [KernelFunction, Description("Describe a specific column: null%, distinct, min/max/avg, examples.")]
//  public async Task<ColumnProfile> DescribeColumn([Description("Column name")] string column)
//  {
//    EnsureTable();
//    var norm = NormalizeName(column);
//    var cols = _schema?.Columns ?? (await BuildSchemaAsync()).Columns;
//    // exact or normalized match
//    var profile = cols.FirstOrDefault(c => string.Equals(c.Name, column, StringComparison.OrdinalIgnoreCase))
//                ?? cols.FirstOrDefault(c => string.Equals(c.Normalized, norm, StringComparison.OrdinalIgnoreCase));
//    if (profile is null) throw new ArgumentException($"Column '{column}' not found");
//    return profile;
//  }

//  // ------------------------ Trend / Query tools -------------------
//  [KernelFunction, Description("Aggregate a time series by granularity with optional dimensions and filters.")]
//  public List<Dictionary<string, object>> TimeSeriesAggregate(
//      [Description("Date/datetime column name")] string dateCol,
//      [Description("Numeric value column to aggregate")] string valueCol,
//      [Description("Granularity: day|week|month|quarter|year")] string granularity = "month",
//      [Description("Aggregation: sum|avg|count|min|max")] string agg = "sum",
//      [Description("Optional SQL WHERE clause (safe, generated by the agent)")] string? where = null,
//      [Description("Optional comma-separated dimension columns to group by")] string? dimsCsv = null,
//      [Description("Max rows to return (cap)")] int maxRows = 200)
//  {
//    EnsureTable();
//    var dims = string.IsNullOrWhiteSpace(dimsCsv) ? Array.Empty<string>() : dimsCsv.Split(',').Select(SanitizeIdent).ToArray();
//    var bucket = $"date_trunc('{SanitizeGranularity(granularity)}', {Ident(dateCol)})";
//    var dimCols = dims.Length == 0 ? string.Empty : ", " + string.Join(", ", dims.Select(Ident));
//    var groupBy = dims.Length == 0 ? "1" : "1, " + string.Join(", ", Enumerable.Range(2, dims.Length));
//    var aggExpr = SanitizeAgg(agg) + "(" + Ident(valueCol) + ") AS value";
//    var sql = $@"SELECT {bucket} AS bucket{dimCols}, {aggExpr}
//                     FROM {_table}
//                     {(string.IsNullOrWhiteSpace(where) ? string.Empty : "WHERE " + where)}
//                     GROUP BY {groupBy}
//                     ORDER BY 1
//                     LIMIT {Math.Clamp(maxRows, 1, 10000)};";
//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = sql;
//    using var rdr = cmd.ExecuteReader();
//    return ReadRows(rdr);
//  }

//  [KernelFunction, Description("Compute rolling metrics (moving average/sum and pct_change) on a time-bucketed series.")]
//  public List<Dictionary<string, object>> MovingWindow(
//      [Description("Subquery or table name providing columns: bucket, value")] string seriesQuery,
//      [Description("Window size in rows (e.g., 7, 30)")] int window = 7,
//      [Description("Emit percentage change column")] bool includePctChange = true,
//      [Description("Max rows to return (cap)")] int maxRows = 2000)
//  {
//    EnsureTable();
//    var w = Math.Clamp(window, 1, 3650);
//    var pct = includePctChange ? ", (value / LAG(value) OVER (ORDER BY bucket) - 1) AS pct_change" : string.Empty;
//    var sql = $@"WITH s AS (
//                        SELECT * FROM ({seriesQuery})
//                     )
//                     SELECT bucket, value,
//                            AVG(value) OVER (ORDER BY bucket ROWS BETWEEN {w - 1} PRECEDING AND CURRENT ROW) AS ma_{w}
//                            {pct}
//                     FROM s
//                     ORDER BY bucket
//                     LIMIT {Math.Clamp(maxRows, 1, 100000)};";
//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = sql;
//    using var rdr = cmd.ExecuteReader();
//    return ReadRows(rdr);
//  }

//  [KernelFunction, Description("Find top contributors by a dimension in a date range.")]
//  public List<Dictionary<string, object>> TopContributors(
//      [Description("Date/datetime column name")] string dateCol,
//      [Description("Numeric value column name")] string valueCol,
//      [Description("Dimension column to group by")] string byDim,
//      [Description("Start date ISO (inclusive)")] string start,
//      [Description("End date ISO (inclusive)")] string end,
//      [Description("Max groups to return")] int k = 10)
//  {
//    EnsureTable();
//    var sql = $@"SELECT {Ident(byDim)} AS key, SUM({Ident(valueCol)}) AS total
//                     FROM {_table}
//                     WHERE {Ident(dateCol)} BETWEEN TIMESTAMP '{Escape(start)}' AND TIMESTAMP '{Escape(end)}'
//                     GROUP BY 1
//                     ORDER BY total DESC
//                     LIMIT {Math.Clamp(k, 1, 1000)};";
//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = sql;
//    using var rdr = cmd.ExecuteReader();
//    return ReadRows(rdr);
//  }

//  [KernelFunction, Description("Run a controlled SELECT with projection/where/order/limit. No SELECT * allowed.")]
//  public List<Dictionary<string, object>> Select(
//      [Description("Comma-separated list of columns to project")] string columnsCsv,
//      [Description("Optional SQL WHERE clause")] string? where = null,
//      [Description("Optional ORDER BY clause")] string? orderBy = null,
//      [Description("Row limit cap")] int limit = 100,
//      [Description("Row offset for pagination")] int offset = 0)
//  {
//    EnsureTable();
//    if (string.IsNullOrWhiteSpace(columnsCsv) || columnsCsv.Contains("*"))
//      throw new ArgumentException("Explicit column list required; SELECT * is not allowed.");

//    var cols = string.Join(", ", columnsCsv.Split(',').Select(Ident));
//    var sql = $@"SELECT {cols} FROM {_table}
//                     {(string.IsNullOrWhiteSpace(where) ? string.Empty : "WHERE " + where)}
//                     {(string.IsNullOrWhiteSpace(orderBy) ? string.Empty : "ORDER BY " + orderBy)}
//                     LIMIT {Math.Clamp(limit, 1, 1000)} OFFSET {Math.Max(0, offset)};";
//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = sql;
//    using var rdr = cmd.ExecuteReader();
//    return ReadRows(rdr);
//  }

//  // ------------------------ Schema/Profile ------------------------
//  private async Task<SchemaCard> BuildSchemaAsync()
//  {
//    EnsureTable();
//    long rows = await ScalarLongAsync($"SELECT COUNT(*) FROM {_table};");

//    // Candidate time columns by type
//    var timeTyped = Query($@"SELECT name FROM duckdb_columns WHERE table_name = '{_table}' AND logical_type IN ('TIMESTAMP','DATE');")
//                    .Select(r => r["name"].ToString()!)
//                    .ToList();

//    // Fallback: name contains date/time tokens
//    var timeByName = Query($"PRAGMA table_info('{_table}');")
//                     .Select(r => r["name"].ToString()!)
//                     .Where(n => Regex.IsMatch(n, "date|time|day|dt", RegexOptions.IgnoreCase))
//                     .ToList();

//    var timeCandidates = timeTyped.Concat(timeByName).Distinct(StringComparer.OrdinalIgnoreCase).ToArray();

//    var columns = new List<ColumnProfile>();
//    foreach (var col in Query($"PRAGMA table_info('{_table}');"))
//    {
//      var name = col["name"].ToString()!;
//      var norm = NormalizeName(name);

//      // Null %, distinct
//      double nullPct = rows == 0 ? 0 : (await ScalarLongAsync($"SELECT SUM(CASE WHEN {Ident(name)} IS NULL THEN 1 ELSE 0 END) FROM {_table};")) / (double)rows;
//      long distinct = await ScalarLongAsync($"SELECT COUNT(DISTINCT {Ident(name)}) FROM {_table};");

//      // Try to infer logical type
//      string logical; string? min = null; string? max = null; double? avg = null; string[]? top = null; string[] examples;
//      var typeRow = Query($"SELECT logical_type FROM duckdb_columns WHERE table_name = '{_table}' AND column_name = '{Escape(name)}';").FirstOrDefault();
//      var duckType = typeRow?["logical_type"].ToString() ?? string.Empty;

//      if (duckType.Contains("TIMESTAMP", StringComparison.OrdinalIgnoreCase) || duckType.Contains("DATE", StringComparison.OrdinalIgnoreCase))
//      {
//        logical = "datetime";
//        var minMax = Query($"SELECT CAST(MIN({Ident(name)}) AS VARCHAR), CAST(MAX({Ident(name)}) AS VARCHAR) FROM {_table};").First();
//        min = minMax.Values.ElementAt(0)?.ToString();
//        max = minMax.Values.ElementAt(1)?.ToString();
//        examples = SampleStrings(name);
//      }
//      else if (duckType.Contains("DECIMAL", StringComparison.OrdinalIgnoreCase) || duckType.Contains("DOUBLE", StringComparison.OrdinalIgnoreCase) || duckType.Contains("INTEGER", StringComparison.OrdinalIgnoreCase))
//      {
//        logical = "double";
//        var minMaxAvg = Query($"SELECT MIN({Ident(name)}), MAX({Ident(name)}), AVG({Ident(name)}) FROM {_table};").First();
//        min = ToStringOrNull(minMaxAvg, 0); max = ToStringOrNull(minMaxAvg, 1); avg = ToDoubleOrNull(minMaxAvg, 2);
//        examples = SampleStrings(name);
//      }
//      else
//      {
//        // string-like: decide categorical vs text by cardinality ratio
//        logical = "text";
//        examples = SampleStrings(name);
//        if (rows > 0)
//        {
//          double cardRatio = distinct / Math.Max(1.0, rows - rows * nullPct);
//          if (cardRatio < 0.2)
//          {
//            logical = "categorical";
//            top = Query($"SELECT {Ident(name)} AS v, COUNT(*) AS c FROM {_table} GROUP BY 1 ORDER BY c DESC LIMIT 5;")
//                  .Select(r => r["v"]?.ToString() ?? "")
//                  .ToArray();
//          }
//        }
//      }

//      columns.Add(new ColumnProfile(name, norm, logical, nullPct, distinct, min, max, avg, top, examples));
//    }

//    return new SchemaCard(rows, timeCandidates, columns);
//  }

//  // ------------------------ Helpers -------------------------------
//  private void NormalizeColumnNames()
//  {
//    // DuckDB preserves original names; create a view with safe identifiers if needed.
//    var cols = Query($"PRAGMA table_info('{_table}');")
//               .Select(r => r["name"].ToString()!)
//               .ToArray();
//    // No-op here; we rely on Ident() to quote safely per usage.
//  }

//  private void EnsureTable()
//  {
//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = $"SELECT 1 FROM information_schema.tables WHERE table_name = '{_table}';";
//    using var rdr = cmd.ExecuteReader();
//    if (!rdr.Read()) throw new InvalidOperationException($"Session table '{_table}' not loaded.");
//  }

//  private void EnsureSchema()
//  {
//    if (_schema is null) throw new InvalidOperationException("Schema not built yet. Call LoadCsvAsync() first.");
//  }

//  private static string SanitizeIdent(string s) => Regex.Replace(s, "[^A-Za-z0-9_]+", "_");
//  private static string NormalizeName(string name) => Regex.Replace(name.Trim().ToLowerInvariant(), "[\n\r\t ]+", "_");
//  private static string Ident(string name)
//  {
//    // Quote identifiers to remain safe with spaces/special chars
//    return "\"" + name.Replace("\"", "\"\"") + "\"";
//  }
//  private static string Escape(string literal) => literal.Replace("'", "''");
//  private static string Bool(bool v) => v ? "TRUE" : "FALSE";
//  private static string SanitizeGranularity(string g)
//  {
//    return g.ToLowerInvariant() switch
//    {
//      "day" => "day",
//      "week" => "week",
//      "month" => "month",
//      "quarter" => "quarter",
//      "year" => "year",
//      _ => "month"
//    };
//  }
//  private static string SanitizeAgg(string a)
//  {
//    return a.ToLowerInvariant() switch
//    {
//      "sum" => "SUM",
//      "avg" or "mean" => "AVG",
//      "count" => "COUNT",
//      "min" => "MIN",
//      "max" => "MAX",
//      _ => "SUM"
//    };
//  }

//  private static List<Dictionary<string, object>> ReadRows(IDataReader reader)
//  {
//    var results = new List<Dictionary<string, object>>();
//    var schema = new List<string>();
//    for (int i = 0; i < reader.FieldCount; i++) schema.Add(reader.GetName(i));
//    while (reader.Read())
//    {
//      var row = new Dictionary<string, object>(schema.Count, StringComparer.OrdinalIgnoreCase);
//      foreach (var col in schema)
//      {
//        var value = reader[col];
//        row[col] = value == DBNull.Value ? null! : value;
//      }
//      results.Add(row);
//    }
//    return results;
//  }

//  private List<Dictionary<string, object>> Query(string sql)
//  {
//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = sql;
//    using var rdr = cmd.ExecuteReader();
//    return ReadRows(rdr);
//  }

//  private async Task<long> ScalarLongAsync(string sql)
//  {
//    using var cmd = _conn.CreateCommand();
//    cmd.CommandText = sql;
//    var o = await cmd.ExecuteScalarAsync();
//    return Convert.ToInt64(o);
//  }

//  private static string? ToStringOrNull(Dictionary<string, object> row, int index)
//  {
//    var val = row.Values.ElementAt(index);
//    return val is null || val == DBNull.Value ? null : val.ToString();
//  }
//  private static double? ToDoubleOrNull(Dictionary<string, object> row, int index)
//  {
//    var val = row.Values.ElementAt(index);
//    if (val is null || val == DBNull.Value) return null;
//    if (double.TryParse(val.ToString(), out var d)) return d;
//    return null;
//  }

//  private string[] SampleStrings(string col, int n = 3)
//  {
//    var rows = Query($"SELECT CAST({Ident(col)} AS VARCHAR) AS v FROM {_table} WHERE {Ident(col)} IS NOT NULL LIMIT {Math.Clamp(n, 1, 10)};");
//    return rows.Select(r => (r["v"]?.ToString() ?? string.Empty).Length > 80
//                            ? (r["v"]!.ToString()![..80] + "…")
//                            : (r["v"]?.ToString() ?? string.Empty)).ToArray();
//  }

//  // ------------------------ Dispose -------------------------------
//  public async ValueTask DisposeAsync()
//  {
//    try { _conn?.Dispose(); } catch { /* ignore */ }
//    if (_tempCsvPath is not null)
//    {
//      try { File.Delete(_tempCsvPath); } catch { /* ignore */ }
//    }
//    await Task.CompletedTask;
//  }
//}

/*
USAGE (registration with Semantic Kernel):

var builder = Kernel.CreateBuilder();
// ... add your AI service here
await using var tool = new SessionCsvAgent();
await tool.LoadCsvAsync(uploadedStream);

builder.Plugins.AddFromObject(tool, pluginName: "csv");
var kernel = builder.Build();

// Now the LLM can call:
// - csv.GetSchemaCard
// - csv.ListColumns
// - csv.DescribeColumn
// - csv.TimeSeriesAggregate
// - csv.MovingWindow
// - csv.TopContributors
// - csv.Select

*/
